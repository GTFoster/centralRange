---
title: "TITLE"
author: "AUTHORS"
includes:
  in_header:
    - \usepackage{lmodern}
output:
  pdf_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    toc: yes
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    theme: journal
---


```{r}
library(igraph)
#library(dplyr)
#library(ggplot2)
library(gridExtra)
library(rgbif)
library(curl)
#library(tidyr)
library(jsonlite)
library(tidyverse)
library(taxize)
```

Let's start with querying WOL for plant-pollinator datasets. 


Querying the web of life API. 
Tutorial for how to do this found here: https://www.web-of-life.es/tutorial/session-download-data.html
```{r}
# define the base url
base_url <- "https://www.web-of-life.es/"   
json_url2 <- paste0(base_url,"get_networks.php?interaction_type=Pollination") 

WolPols <- jsonlite::fromJSON(json_url2)
WolMeta <- read.csv(paste0(base_url,"get_network_info.php")) %>%dplyr::filter(., network_type%in%"Pollination")
length(unique(WolPols$network_name)) # 174 Networks

WolMeta <- read.csv(paste0(base_url,"get_network_info.php"))
WolMeta <- WolMeta %>% dplyr::filter(., network_type%in%"Pollination") #Make sure we have only pollination
WolMeta <- WolMeta %>% 
  #dplyr::select(., network_name, region, latitude, longitude) %>% 
  left_join(WolPols, ., by="network_name")
```

Let's do some double checking to 
1) Separate vertebrate from invertebrate pollination networks
%2) Make different sources are correctly harmonized #Turns out these are the new deal

I was first going check every taxa with taxize, but turns out this actually takes a long time to run with so many taxa. Instead, I looked at the original papers for the 74 publications included in these data. Slow, but still faster than taxize. I load in the key I created for that below. 

```{r}
studykey <- read.csv(file="studykey.csv")
WolMeta <- left_join(WolMeta, studykey, by=c("author", "reference"))

WolMeta<- dplyr::filter(WolMeta, grepl("Unidentified", species2, ignore.case=F)==F) #remove unidentified
WolMeta<- dplyr::filter(WolMeta, grepl(" sp[1-9]+", species2, ignore.case=F)==F) #remove those with polls identified to genera only
WolMeta<- dplyr::filter(WolMeta, grepl(" sp[1-9]+", species1, ignore.case=F)==F) #remove those plants identified to genera only
#Interesting to evaluate whether to do this on a local level, but necessary with global metaweb (sp1 in one network may be sp2 in another, etc)

mixedwebs <- dplyr::filter(WolMeta, Taxa=="Mixed")
Insectweb <- dplyr::filter(WolMeta, Taxa=="Insecta")
Birdweb <- dplyr::filter(WolMeta, Taxa=="Aves")

Insectweb <- dplyr::filter(mixedwebs, grepl(c("Apis"), species2)==T | grepl(c("Ornidia"), species2)==T | grepl(c("Bombus"), species2)==T | grepl(c("Musca"), species2)==T ) %>% rbind(Insectweb, .) #Add in some common insect genera from mixed webs

mixedwebs <- dplyr::filter(mixedwebs, grepl(c("Apis"), species2)==F & grepl(c("Ornidia"), species2)==F & grepl(c("Bombus"), species2)==F & grepl(c("Musca"), species2)==F ) #Remove these from the to-query group


mixedord <- tax_name(unique(mixedwebs$species2), get = "class", db = "ncbi")

missing <- dplyr::filter(mixedord, is.na(class)==T)
missing$query[missing$query=="Politmus milleri"] <- "Polytmus milleri" #Mispelled bird
missing$query[missing$query=="Physiphoa azurea"] <- "Physiphora azurea " #Mispelled fly

missing$gen <- gsub( " .*$", "", missing$query) 
gens <- data.frame(gen=missing$gen, class=NA) %>% unique()
gens <- dplyr::filter(gens, gen %in% c("Clamirius", "Eurymetopun")==F) #Can't find these

gens$class[gens$gen%in%c("Amazilia", "Carduelis", "Foudia", "Polytmus")] <- "Aves" #The birds in the list
gens$class[is.na(gens$class)==T] <- "Insect" #Everything left is an insect 

missing <- missing %>% dplyr::select(., -class) %>% left_join(., gens, by="gen") %>% na.omit() #Grab the missing classes

Birdweb  <- dplyr::filter(mixedwebs, species2 %in% missing$query[missing$class=="Aves"]) %>%
  rbind(Birdweb,.)
Insectweb <- dplyr::filter(mixedwebs, species2 %in% missing$query[missing$class=="Insecta"]) %>%
  rbind(Insectweb,.)

```

Now that we've done our filtering, let's check out our two created metawebs
```{r}
InsectMeta <- dplyr::select(Insectweb, species1, species2) %>% unique()
imeta <- igraph::graph_from_data_frame(InsectMeta, directed=F) #Create idgraph object


BirdMeta <- dplyr::select(Birdweb, species1, species2) %>% unique()
bmeta <- igraph::graph_from_data_frame(BirdMeta, directed=F) #Create idgraph object
```


Need to remove species not located in the main component of the metaweb (otherwise can't compute centrality)
```{r}
V(imeta)$component <- components(imeta)$membership
components(imeta)$csize #Largest component has 6237 nodes; the rest are isolated pairs
imeta <- delete.vertices(imeta, V(imeta)$component[V(imeta)$component!=which.max(components(imeta)$csize)]) #Remove vertices that aren't included in the largest component

V(bmeta)$component <- components(bmeta)$membership
components(bmeta)$csize #Largest component has 721 nodes; the rest are isolated pairs
bmeta <- delete.vertices(bmeta, V(bmeta)$component[V(bmeta)$component!=which.max(components(bmeta)$csize)]) #Remove vertices that aren't included in the largest component
```


Let's calculate our measures of species centrality in the metaweb

```{r}
imetaCent <- data.frame(between=igraph::centralization.betweenness(imeta)$res,
           close=igraph::centralization.closeness(imeta)$res,
           deg=igraph::centralization.degree(imeta, mode="all")$res,
           eig=igraph::centralization.evcent(imeta)$vector,
           node=V(imeta)$name)

bmetaCent <- data.frame(between=igraph::centralization.betweenness(bmeta)$res,
           close=igraph::centralization.closeness(bmeta)$res,
           deg=igraph::centralization.degree(bmeta, mode="all")$res,
           eig=igraph::centralization.evcent(bmeta)$vector,
           node=V(bmeta)$name)

## Use n equally spaced breaks to assign each value to n-1 equal sized bins 
ii <- cut(bmetaCent$eig, breaks = seq(min(bmetaCent$eig, na.rm=T), max(bmetaCent$eig, na.rm=T), len = 100), 
          include.lowest = TRUE)

## Use bin indices, ii, to select color from vector of n-1 equally spaced colors
V(bmeta)$color <- colorRampPalette(c("lightblue", "blue"))(99)[ii]


plot(bmeta, vertex.label=NA, layout=layout_nicely)
```




```{r}
overlaps <- dplyr::filter(bmetaCent, node %in% imetaCent$node)

overlaps <- imetaCent %>% dplyr::select(node, deg, eig, close) %>% dplyr::rename(., insect_deg=deg, insect_eig=eig, insect_close=close) %>% left_join(overlaps, ., by="node")

plot(overlaps$eig, overlaps$insect_eig, xlab="Eigenvalue Centrality in Bird Network", ylab="Eigenvalue Centrality in Insect Network")
cor.test(overlaps$eig, overlaps$insect_eig)
plot(overlaps$deg, overlaps$insect_deg, xlab="Degree in Bird Network", ylab="Degree in Insect Network")
cor.test(overlaps$deg, overlaps$insect_deg)

plot(overlaps$close, overlaps$insect_close, xlab="Closeness in Bird Network", ylab="Closeness in Insect Network")
cor.test(overlaps$close, overlaps$insect_close)
```


```{r}
sp <- unique(imetaCent$node, bmetaCent$node)
length(sp)
```



```{r}
fls <- list.files(path="data/GBIF/occs/") #Grab all the filenames in our occurence data dir
nms <- gsub("_", " ", fls) %>% gsub(".csv", "", .) #Refit to match data
nms <- paste(toupper(substr(nms, 1,1)), substr(nms,2,100), sep="")

table(nms%in% c(BirdMeta$species1, BirdMeta$species2, InsectMeta$species1, InsectMeta$species2))
```

```{r}
library(gbifdb)

# the below folder will change depending on when you download the gbif data using the above command
gbif <- gbif_local(dir='../../../GBIF_local/occurrence/2024-04-01')
#gbif_local(dir='~/GBIF_local/occurrence/2024-04-01')
# dbDisconnect()


gbifdb::gbif_version(gbif)



occs <- gbif |> 
  #group_by(species) |> 
  filter(species == "Eupatorium macrocephalum") |> 
	#filter(!is.na(decimallatitude)) |> 
	#count(class) |> 
	collect()

occs2 <- as.data.frame(dplyr::filter(occs, n > 100)) 

record <- rgbif::occ_search(scientificName = name, hasGeospatialIssue=FALSE)
```


##START HERE: UPDATING RANGE SIZING QUERY

```{r}
pear_mat <- cor(metaCent, method="pearson", use="complete.obs")
spearmat <- cor(metaCent, method="spearman", use="complete.obs")

hist(metaCent$close)
plot(metaCent$close, metaCent$between)
plot(metaCent$close, metaCent$degree)
plot(metaCent$close, metaCent$eig)

parpl <- list()
for(j in 1:4){
parpl[[j]] <- ggplot(metaCent, aes(x=metaCent[,1], y=metaCent[,j]))+geom_point()+xlab("between")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+4]] <- ggplot(metaCent, aes(x=metaCent[,2], y=metaCent[,j]))+geom_point()+xlab("close")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+8]] <- ggplot(metaCent, aes(x=metaCent[,3], y=metaCent[,j]))+geom_point()+xlab("deg")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+12]] <- ggplot(metaCent, aes(x=metaCent[,4], y=metaCent[,j]))+geom_point()+xlab("eig")+ylab(colnames(metaCent)[j])
}

#pdf(file="figs/PairwiseCors.pdf", width=11, height=11)
grid.arrange(parpl[[1]], 
             parpl[[2]], 
             parpl[[3]],
             parpl[[4]],
             parpl[[5]],
             parpl[[6]],
             parpl[[7]],
             parpl[[8]],
             parpl[[9]],
             parpl[[10]],
             parpl[[11]],
             parpl[[12]],
             parpl[[13]],
             parpl[[14]],
             parpl[[15]],
             parpl[[16]],
             nrow = 4)
#dev.off()


#pdf(file="figs/CentralityCorrelations.pdf", width=8, height=4)
par(mfrow = c(1, 2))
corrplot::corrplot(pear_mat, type = "lower", diag=T, main="Pearson's Correlation", mar=c(0,0,2,0), method="ellipse")
corrplot::corrplot(spearmat, type = "lower", diag=T, main="Spearman's Correlation", mar=c(0,0,2,0), method="ellipse")
#dev.off()
```


Set up the function to query GBIF occurance points and filter some obviously problematic ones.
```{r}
metaCent$node <- names(imetaC[1]) #Assign node names in metaweb to centrality measures
#save(metaCent, file="data/MetaWebCentrality.Rda")

#Maybe this will solve curl issues? Honestly not sure :(
#curl::handle_setopt(new_handle(),http_version = 2)
curlopts=list(http_version=2)
gbifQueryfilter <- function(name){
  #curl::handle_setopt(new_handle(),http_version = 2)
  record <- rgbif::occ_search(scientificName = name, hasGeospatialIssue=FALSE)
  #curl::handle_setopt(new_handle(),http_version = 2)
  keynum <- rgbif::name_backbone(name)$usageKey
  #curl::handle_setopt(new_handle(),http_version = 2)
  gbif_download <- occ_download(pred("taxonKey", keynum),format = "SIMPLE_CSV", user="riverman12", pwd="1Chicken!!!", email="fostergt@email.sc.edu")
  
  #curl::handle_setopt(new_handle(),http_version = 2)
  occ_download_wait(gbif_download)
  #curl::handle_setopt(new_handle(),http_version = 2)
  spdat <- occ_download_get(gbif_download, path="data/GBIF/") %>%
    occ_download_import()
  
spdat <- spdat %>%
    dplyr::filter(occurrenceStatus  == "PRESENT") %>%
    dplyr::filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN")) %>% #Remove fossils
    CoordinateCleaner::cc_cen( #Remove records within 2k buffer of country centroids
    lon = "decimalLongitude", 
    lat = "decimalLatitude", 
    buffer = 2000, # radius of circle around centroid to look for centroids
    value = "clean",
    test="both")  %>% 
    cc_sea( #Remove oceanic records
  lon = "decimalLongitude",
  lat = "decimalLatitude"
  ) %>%
  dplyr::filter(., establishmentMeans != "introduced") #Remove known introduced spp

occs <- dplyr::select(spdat, genus, species,scientificName, decimalLatitude, decimalLongitude) %>% unique()

filname <- name %>% tolower() %>% gsub(pattern=" ", replacement="_",.) %>%
  paste("data/GBIF/occs/", ., ".csv", sep="")
write.csv(occs, file=filname, row.names = FALSE)
}
```




