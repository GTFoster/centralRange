---
title: "TITLE"
author: "AUTHORS"
includes:
  in_header:
    - \usepackage{lmodern}
output:
  pdf_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    toc: yes
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    theme: journal
---


Let's check out Mangal and see if we can get some more points
```{r}
library(rmangal)
library(igraph)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(rgbif)
library(curl)
library(tidyr)
```

4499	4529	
```{r eval=FALSE}
mgs <- rmangal::search_datasets("pollinator")
mgn <- rmangal::get_collection(mgs)

#save(mgn, amPol, file="data/Mangel_Wol_Query.Rda")
```

```{r}
load("data/Mangel_Wol_Query.Rda")
```

#amPol is from WOL
#mgn is from Mangel

```{r}

#Creating global meta web from Mangal Data
output <- NULL
for(i in 1:length(mgn)){
  temp_inters <- as_long_data_frame(igraph::as.igraph(mgn[[i]]))
  temp_inters <- temp_inters %>% dplyr::select(., to_taxonomy.name, from_taxonomy.name, to_taxonomy.gbif, from_taxonomy.gbif, network_id) %>% unique()
  output <- rbind(output, temp_inters)
}
#nrow(output) #Total number of interactions
#length(unique(output$network_id))
```


```{r}
temp <- output %>% dplyr::filter(., is.na(to_taxonomy.gbif)==FALSE & is.na(from_taxonomy.gbif)==FALSE) %>% unique()
colnames(temp)
temp$interaction <- 1




# Expand the dataframe to include all pairwise combinations within each network - this code courtesy of chatGPT
expanded_df <- temp %>%
  group_by(network_id) %>%
  nest() %>%
  mutate(combinations = purrr::map(data, ~ {
    plants <- unique(.x$to_taxonomy.name)
    pollinators <- unique(.x$from_taxonomy.name)
    expand.grid(from_taxonomy.name = pollinators, to_taxonomy.name = plants)
  })) %>%
  unnest(combinations) %>%
  select(-data)

res <- left_join(expanded_df, temp, by = join_by(network_id, from_taxonomy.name, to_taxonomy.name))
res$interaction[is.na(res$interaction)==T] <- 0
```


```{r}

counts <- res %>% dplyr::mutate(., speciesPair=paste(to_taxonomy.name, from_taxonomy.name, sep="-")) %>%
  group_by(., speciesPair) %>%
  dplyr::summarise(., pos=sum(interaction), tot=n(), neg=tot-pos)

counts$prop <- counts$pos/counts$tot  

counts <- res %>% dplyr::mutate(., speciesPair=paste(to_taxonomy.name, from_taxonomy.name, sep="-")) %>% dplyr::select(from_taxonomy.name, to_taxonomy.name, speciesPair) %>% unique() %>% left_join(counts, ., by="speciesPair")


usable_pollen <- dplyr::filter(counts, tot>4, prop>0)
length(unique(usable_pollen$from_taxonomy.name))
length(unique(usable_pollen$to_taxonomy.name))

length(unique(usable$Frugivore_Species))
length(unique(usable$Plant_Species))

colnames(usable_pollen)
colnames(usable)
```

Alright, now we have a set of species that coocur in some networks but interact and cooccur in others. First let's extract our geometries for each network.
```{r}
geomtypes <- vector()
for(i in 1:324){
  geomtypes[i] <- mgn[[i]]$network$geom_type
}


sites <- NULL
for(i in 1:324){
  if(is.na(geomtypes[i])==F){
    ret <- data.frame(network_id=mgn[[i]]$network$network_id, lon=mgn[[i]]$network$geom_lon[[1]], "lat"=mgn[[i]]$network$geom_lat[[1]], size=nrow(mgn[[i]]$nodes)) %>% dplyr::summarise(network_id=mean(network_id), lon=mean(lon), lat=mean(lat), size=mean(size))
  sites <- rbind(sites, ret)
  
  mgn[[10]]$nodes
  }
}



world <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf")

ggplot(data = world) +
    geom_sf()+theme_classic()+geom_point(data=sites, aes(x=lon, y=lat))

plot(x=sites$lon, y=sites$lat)

sites
usable_pollen <- left_join(usable_pollen, sites, by="network_id")
usable_pollen <- dplyr::filter(usable_pollen, is.na(lon)==F)

usable_pollen <- dplyr::rename(usable_pollen, Animal_Species=from_taxonomy.name, Plant_Species=to_taxonomy.name)
usable_pollen <- dplyr::rename(res, Animal_Species=from_taxonomy.name, Plant_Species=to_taxonomy.name) %>% select(., network_id, Animal_Species, Plant_Species, interaction) %>% unique() %>% left_join(usable_pollen, ., by=c("network_id", "Animal_Species", "Plant_Species"))


length(unique(usable_pollen$from_taxonomy.name))
length(unique(usable_pollen$to_taxonomy.name))


usable_pollen$type <- "pollen"
usable_p <- dplyr::select(usable_pollen, -network_id)
usable_p <- dplyr::rename(usable, Animal_Species=Frugivore_Species, nAnimals=nbirds)
usable$size <- usable$nAnimals+usable$nplants

usable_p$nAnimals <- NA
usable_p$nplants <- NA

colnames(usable) %in% colnames(usable_p)

testpoints <- rbind(usable, usable_p)
?complete.cases()
testpoints <- testpoints[complete.cases(testpoints$Latitude)==T,]
save(testpoints, file ="data/TestPoints.Rda")
```


```{r}
metaweb <- output %>% dplyr::filter(., is.na(to_taxonomy.gbif)==FALSE & is.na(from_taxonomy.gbif)==FALSE) %>% dplyr::select(., -network_id) %>% unique()
class(metaweb)
rownames(metaweb) <- 1:nrow(metaweb)

imeta <- igraph::graph_from_data_frame(metaweb, directed=F) #Create idgraph object
```

Let's drop nodes from disconnected components
```{r}
V(imeta)$component <- components(imeta)$membership
components(imeta)$csize #Largest component has 959 nodes; the rest are orders of magnitude smaller



imetaC <- delete.vertices(imeta, V(imeta)$component[V(imeta)$component!=which.max(components(imeta)$csize)]) #Removevertices that aren't included in the largest component
```



```{r}
colnames(metaweb)



metaweb %>% dplyr::mutate(., speciesPair=paste(to_taxonomy.name, to_taxonomy.name, sep="-")) %>%
  group_by(., speciesPair) %>%
  dplyr::summarise(., pos=sum(interaction), tot=n(), neg=tot-pos)


counts <- Moulatletval %>% dplyr::mutate(., speciesPair=paste(Frugivore_Species, Plant_Species, sep="-")) %>%
  group_by(., speciesPair) %>%
  dplyr::summarise(., pos=sum(interaction), tot=n(), neg=tot-pos)
```



```{r}
#igraph::centralization.betweenness(imetaC)
#igraph::centralization.closeness(imetaC)
#igraph::centralization.degree(imetaC, mode="all")
#igraph::centralization.evcent(imetaC)

metaCent <- data.frame(between=igraph::centralization.betweenness(imetaC)$res,
           close=igraph::centralization.closeness(imetaC)$res,
           deg=igraph::centralization.degree(imetaC, mode="all")$res,
           eig=igraph::centralization.evcent(imetaC)$vector)
```

```{r}
pear_mat <- cor(metaCent, method="pearson", use="complete.obs")
spearmat <- cor(metaCent, method="spearman", use="complete.obs")

hist(metaCent$close)
plot(metaCent$close, metaCent$between)
plot(metaCent$close, metaCent$degree)
plot(metaCent$close, metaCent$eig)

parpl <- list()
for(j in 1:4){
parpl[[j]] <- ggplot(metaCent, aes(x=metaCent[,1], y=metaCent[,j]))+geom_point()+xlab("between")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+4]] <- ggplot(metaCent, aes(x=metaCent[,2], y=metaCent[,j]))+geom_point()+xlab("close")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+8]] <- ggplot(metaCent, aes(x=metaCent[,3], y=metaCent[,j]))+geom_point()+xlab("deg")+ylab(colnames(metaCent)[j])
}
for(j in 1:4){
parpl[[j+12]] <- ggplot(metaCent, aes(x=metaCent[,4], y=metaCent[,j]))+geom_point()+xlab("eig")+ylab(colnames(metaCent)[j])
}

#pdf(file="figs/PairwiseCors.pdf", width=11, height=11)
grid.arrange(parpl[[1]], 
             parpl[[2]], 
             parpl[[3]],
             parpl[[4]],
             parpl[[5]],
             parpl[[6]],
             parpl[[7]],
             parpl[[8]],
             parpl[[9]],
             parpl[[10]],
             parpl[[11]],
             parpl[[12]],
             parpl[[13]],
             parpl[[14]],
             parpl[[15]],
             parpl[[16]],
             nrow = 4)
#dev.off()


#pdf(file="figs/CentralityCorrelations.pdf", width=8, height=4)
par(mfrow = c(1, 2))
corrplot::corrplot(pear_mat, type = "lower", diag=T, main="Pearson's Correlation", mar=c(0,0,2,0), method="ellipse")
corrplot::corrplot(spearmat, type = "lower", diag=T, main="Spearman's Correlation", mar=c(0,0,2,0), method="ellipse")
#dev.off()
```


Set up the function to query GBIF occurance points and filter some obviously problematic ones.
```{r}
metaCent$node <- names(imetaC[1]) #Assign node names in metaweb to centrality measures
#save(metaCent, file="data/MetaWebCentrality.Rda")

#Maybe this will solve curl issues? Honestly not sure :(
#curl::handle_setopt(new_handle(),http_version = 2)
curlopts=list(http_version=2)
gbifQueryfilter <- function(name){
  #curl::handle_setopt(new_handle(),http_version = 2)
  record <- rgbif::occ_search(scientificName = name, hasGeospatialIssue=FALSE)
  #curl::handle_setopt(new_handle(),http_version = 2)
  keynum <- rgbif::name_backbone(name)$usageKey
  #curl::handle_setopt(new_handle(),http_version = 2)
  gbif_download <- occ_download(pred("taxonKey", keynum),format = "SIMPLE_CSV", user="riverman12", pwd="1Chicken!!!", email="fostergt@email.sc.edu")
  
  #curl::handle_setopt(new_handle(),http_version = 2)
  occ_download_wait(gbif_download)
  #curl::handle_setopt(new_handle(),http_version = 2)
  spdat <- occ_download_get(gbif_download, path="data/GBIF/") %>%
    occ_download_import()
  
spdat <- spdat %>%
    dplyr::filter(occurrenceStatus  == "PRESENT") %>%
    dplyr::filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN")) %>% #Remove fossils
    CoordinateCleaner::cc_cen( #Remove records within 2k buffer of country centroids
    lon = "decimalLongitude", 
    lat = "decimalLatitude", 
    buffer = 2000, # radius of circle around centroid to look for centroids
    value = "clean",
    test="both")  %>% 
    cc_sea( #Remove oceanic records
  lon = "decimalLongitude",
  lat = "decimalLatitude"
  ) %>%
  dplyr::filter(., establishmentMeans != "introduced") #Remove known introduced spp

occs <- dplyr::select(spdat, genus, species,scientificName, decimalLatitude, decimalLongitude) %>% unique()

filname <- name %>% tolower() %>% gsub(pattern=" ", replacement="_",.) %>%
  paste("data/GBIF/occs/", ., ".csv", sep="")
write.csv(occs, file=filname, row.names = FALSE)
}
```

Apply it for each node species
```{r}
for(i in 1:length(metaCent$node)){
  gbifQueryfilter(metaCent$node[i])
}
```


